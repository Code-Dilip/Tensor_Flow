{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eba946bc-ee69-4053-8ca8-ef0c61421e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 21:41:18.140424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# First import the necessary libraries\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f63bf72-5a8a-43d3-8c30-1fa22551028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of base_dir: cats_and_dogs_filtered\n",
      "Contents of train_dir: cats_and_dogs_filtered/train\n",
      "Contents of validation_dir: cats_and_dogs_filtered/validation\n",
      "\n",
      "Contents of validation_cats_dir: cats_and_dogs_filtered/validation/cats\n",
      "Contents of validation_dogs_dir: cats_and_dogs_filtered/validation/dogs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'cats_and_dogs_filtered'\n",
    "\n",
    "train_dir = os.path.join(base_dir,'train')\n",
    "validation_dir = os.path.join(base_dir,'validation')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir,'cats')\n",
    "train_dogs_dir = os.path.join(train_dir,'dogs')\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir,'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir,'dogs')\n",
    "\n",
    "print(\"Contents of base_dir:\",base_dir)\n",
    "print(\"Contents of train_dir:\",train_dir)\n",
    "print(\"Contents of validation_dir:\",validation_dir)\n",
    "print()\n",
    "print(\"Contents of validation_cats_dir:\",validation_cats_dir)\n",
    "print(\"Contents of validation_dogs_dir:\",validation_dogs_dir)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04df04d2-7b16-4856-a94d-67670da433eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cats_fnames = os.listdir(train_cats_dir)\n",
    "train_dogs_fnames = os.listdir(train_dogs_dir)\n",
    "\n",
    "validation_cats_fnames = os.listdir(validation_cats_dir)\n",
    "validation_dogs_fnames = os.listdir(validation_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfed0e2d-c11c-433d-bf6c-a3ba46775d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_cats_fnames[0:5]: ['cat.803.jpg', 'cat.464.jpg', 'cat.882.jpg', 'cat.779.jpg', 'cat.194.jpg']\n",
      "train_dogs_fnames[0:5]: ['dog.917.jpg', 'dog.795.jpg', 'dog.734.jpg', 'dog.715.jpg', 'dog.105.jpg']\n",
      "\n",
      "validation_cats_fnames[0:5]: ['cat.2270.jpg', 'cat.2321.jpg', 'cat.2216.jpg', 'cat.2414.jpg', 'cat.2498.jpg']\n",
      "validation_dogs_fnames[0:5]: ['dog.2141.jpg', 'dog.2449.jpg', 'dog.2363.jpg', 'dog.2097.jpg', 'dog.2038.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(\"train_cats_fnames[0:5]:\",train_cats_fnames[0:5])\n",
    "print(\"train_dogs_fnames[0:5]:\",train_dogs_fnames[0:5])\n",
    "print()\n",
    "print(\"validation_cats_fnames[0:5]:\",validation_cats_fnames[0:5])\n",
    "print(\"validation_dogs_fnames[0:5]:\",validation_dogs_fnames[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a529d41-544c-4875-814c-4549fbb2f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape = (150,150,3)),\n",
    "        tf.keras.layers.Rescaling(.1/255),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16,(3,3),activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(32,(3,3),activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512,activation = 'relu'),\n",
    "        tf.keras.layers.Dense(1,activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1834e6cd-d859-4fa6-91cd-2ab6c65623a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 21:58:59.814534: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "untrained_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "367760b7-01b9-40a9-ba36-fba7898b3999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 150, 150, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 148, 148, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18496)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               9470464   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,494,561\n",
      "Trainable params: 9,494,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(untrained_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cc8f5f8-f7ac-4503-a411-5ea7f919249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size =  (150,150),\n",
    "    batch_size = 20,\n",
    "    label_mode = 'binary'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    image_size = (150,150),\n",
    "    batch_size = 20,\n",
    "    label_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36100ee8-3f50-43a5-8132-96dca25fa585",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_buffer_size = 1000\n",
    "prefetch_buffer_size = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset_final = train_dataset.cache().shuffle(buffer_size = shuffle_buffer_size).prefetch(buffer_size = prefetch_buffer_size)\n",
    "validation_dataset_final = validation_dataset.cache().shuffle(buffer_size = shuffle_buffer_size).prefetch(buffer_size = prefetch_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54f0afee-90e1-49fd-85ca-111e1b06fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = untrained_model.compile(\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate = 0.001),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb47d1c-3a42-4d7d-87f9-5efc9adc828a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
